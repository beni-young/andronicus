# My notebook title

Date: 2018-06-01  
Author: firstname lastname  
Categories: category1, category2  
Tags: tag1, tag2, tag3  
<!--eofm-->

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5ec0ba1",
   "metadata": {},
   "source": [
    "This scraper is going to be used to find African American Film Directors from combining information from Wikipedia and IMDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbee01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from imdb import Cinemagoer\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dc16f27",
   "metadata": {},
   "source": [
    "## This creates the Director's list from both wikipedia pages\n",
    "Its going through each hyperlink on the wikipedia website and adds them to a list. It is broken up into two variables director_links\n",
    "and director_links2 to make sure to get all the directors from A-Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6918b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Category:African-American_film_directors\"\n",
    "url2 = \"https://en.wikipedia.org/w/index.php?title=Category:African-American_film_directors&from=P\"\n",
    "movie_list = set()\n",
    "director_films = set()\n",
    "testing_list = []\n",
    "names = []\n",
    "\n",
    "# this will take out names that are organizations and take out the added identifiers at the end of names\n",
    "name_exclude = ['Black women filmmakers', 'Pioneers of African-American Cinema']\n",
    "name_check = ['film director', 'filmmaker', 'director', 'writer', 'actor', 'musician']\n",
    "\n",
    "# parsing out the <a> tags \n",
    "def director_page(url):\n",
    "    try:\n",
    "        result = requests.get(url)\n",
    "        result.raise_for_status()\n",
    "        doc = BeautifulSoup(result.text, \"html.parser\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return doc.find(class_=\"mw-category mw-category-columns\").find_all('a')\n",
    "\n",
    "\n",
    "director_links = director_page(url)\n",
    "director_links2 = director_page(url2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69066591",
   "metadata": {},
   "source": [
    "### Creates a list of (Director Names, Wikipedia Link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9330e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Directors(names, object):    \n",
    "    for director in object:\n",
    "        if any(y in director.string for y in name_exclude):\n",
    "            director.string = ''\n",
    "        elif any(x in director.string for x in name_check):\n",
    "            director.string  = director.string.rsplit('(', 1)[0]\n",
    "\n",
    "        if director.string or director.string in names: \n",
    "            #         LIST:    NAME                       WIKI_LINK\n",
    "            names.append([str(director.string.rstrip()), \"https://en.wikipedia.org\" + director['href']])        \n",
    "    return names \n",
    "\n",
    "names = Directors(names, director_links)\n",
    "names = Directors(names, director_links2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc4486f4",
   "metadata": {},
   "source": [
    "### Creates the Dataframe with Name and Wiki_Link Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "443ea245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>wiki_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdisalam Aato</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abdisalam_Aato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gay Abel-Bey</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Gay_Abel-Bey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fathia Absie</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Fathia_Absie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anita W. Addison</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Anita_W._Addison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Omowale Akintunde</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Omowale_Akintunde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Tricia Woodgett</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tricia_Woodgett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Bille Woodruff</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bille_Woodruff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Fronza Woods</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Fronza_Woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Tanya Wright</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tanya_Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Phillip Youmans</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Phillip_Youmans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                                        wiki_link\n",
       "0       Abdisalam Aato     https://en.wikipedia.org/wiki/Abdisalam_Aato\n",
       "1         Gay Abel-Bey       https://en.wikipedia.org/wiki/Gay_Abel-Bey\n",
       "2         Fathia Absie       https://en.wikipedia.org/wiki/Fathia_Absie\n",
       "3     Anita W. Addison   https://en.wikipedia.org/wiki/Anita_W._Addison\n",
       "4    Omowale Akintunde  https://en.wikipedia.org/wiki/Omowale_Akintunde\n",
       "..                 ...                                              ...\n",
       "313    Tricia Woodgett    https://en.wikipedia.org/wiki/Tricia_Woodgett\n",
       "314     Bille Woodruff     https://en.wikipedia.org/wiki/Bille_Woodruff\n",
       "315       Fronza Woods       https://en.wikipedia.org/wiki/Fronza_Woods\n",
       "316       Tanya Wright       https://en.wikipedia.org/wiki/Tanya_Wright\n",
       "317    Phillip Youmans    https://en.wikipedia.org/wiki/Phillip_Youmans\n",
       "\n",
       "[318 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(names, columns=['Name', 'wiki_link'])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e98e4ec4",
   "metadata": {},
   "source": [
    "### Saves the Dataframe as a csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "147cd1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"director_names.csv\")\n",
    "print(len(names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "409a95a4",
   "metadata": {},
   "source": [
    "### This is set up for getting Filmography from Director's Wikipedia page\n",
    "* It first opens up each wikipedia page of the director and checks to see what type of Filmography section or if it has one at all.\n",
    "* Then depending on what type it finds. It will get the list of movies and the year it was released.\n",
    "* In the end, it will create a list with the \"Movie, Year, Wikipedia\" which will be used to identify a director on IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b18d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "director_films = set()\n",
    "test = []\n",
    "mxm = []\n",
    "\n",
    "#The range is performed in set of 50 to avoid timeout issues and to test if the data is pulled\n",
    "#the total range is 311 which is the len(names)\n",
    "for i in range(0, len(names)-1): \n",
    "#for i in range(0, 300): \n",
    "\n",
    "    #add a wait time of 5 seconds so there isn't a timeout\n",
    "    if i % 50 == 0:\n",
    "        time.sleep(5)\n",
    "\n",
    "    wiki_url = \"https://en.wikipedia.org\" + str(df.loc[i].at['wiki_link'])      \n",
    "    table_check = False\n",
    "\n",
    "    try:\n",
    "        result = requests.get(wiki_url)\n",
    "        result.raise_for_status()\n",
    "        doc = BeautifulSoup(result.text, \"html.parser\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    if doc.find(id=\"Filmography\") and doc.find(class_=\"wikitable\"):\n",
    "        if doc.find(id=\"Filmography\").parent.find_next(\"th\").find_next(\"th\").text.rstrip() == \"Title\" or \\\n",
    "           doc.find(id=\"Filmography\").parent.find_next(\"th\").find_next(\"th\").text.rstrip() == \"Film\": \n",
    "            film_list = doc.find(id=\"Filmography\").parent.find_next(\"th\").find_all_next(\"tr\", limit=6)        \n",
    "            table_check = True                  \n",
    "        else:\n",
    "            film_list = doc.find(id=\"Filmography\").parent.find_all_next(\"li\", limit=6)\n",
    "    elif doc.find(id=\"Films\") and doc.find(class_=\"wikitable\"):\n",
    "        if doc.find(id=\"Films\").parent.find_next(\"th\").find_next(\"th\").text.rstrip() == \"Film\": \n",
    "            film_list = doc.find(id=\"Films\").parent.find_next(\"th\").find_all_next(\"tr\", limit=6)        \n",
    "            table_check = True\n",
    "        else:\n",
    "            film_list = doc.find(id=\"Films\").parent.find_all_next(\"li\", limit=6)\n",
    "    elif doc.find(id=\"Filmography\"):\n",
    "        film_list = doc.find(id=\"Filmography\").parent.find_all_next(\"li\", limit=6)\n",
    "    elif doc.find(id=\"Films_2\"):\n",
    "        film_list = doc.find(id=\"Films_2\").parent.find_all_next(\"li\", limit=6)\n",
    "    elif (doc.find(id=\"Films\") or doc.find(id=\"Film\")) and doc.find(class_=\"mw-headline\"):\n",
    "        if doc.find(id=\"Films\"):\n",
    "            film_list = doc.find(id=\"Films\").parent.find_all_next(\"li\", limit=6)            \n",
    "        else:\n",
    "            film_list = doc.find(id=\"Film\").parent.find_all_next(\"li\", limit=6)\n",
    "    elif (doc.find(id=\"Selected_filmography\") or doc.find(id=\"Select_Filmography\")) and doc.find(class_=\"mw-headline\"):\n",
    "        if doc.find(id=\"Selected_filmography\"):\n",
    "            film_list = doc.find(id=\"Selected_filmography\").parent.find_all_next(\"li\", limit=6)\n",
    "        else:\n",
    "            film_list = doc.find(id=\"Select_Filmography\").parent.find_all_next(\"li\", limit=6)\n",
    "    elif doc.find(id=\"Filmography_as_director\") and doc.find(class_=\"mw-headline\"):\n",
    "        film_list = doc.find(id=\"Filmography_as_director\").parent.find_all_next(\"li\", limit=6)\n",
    "    else:\n",
    "        #print(\"Couldn't find one for \", wiki_url)\n",
    "        continue\n",
    "\n",
    "    for film in film_list:\n",
    "        \n",
    "        #Filmography Section has a Film Table: Year Movie and table check is used since it changes the format\n",
    "        if table_check == True:            \n",
    "            if re.search('\\d\\d\\d\\d', film.text):\n",
    "                s = film.text.rsplit('\\n\\n')\n",
    "                if len(s) >= 2:\n",
    "                    t = [s[1].strip(), s[0].lstrip(), wiki_url]\n",
    "                else:\n",
    "                    s[0] = s[0].strip()\n",
    "                    s[0] = re.sub('\\[\\d+\\]',\"\", s[0])\n",
    "                    s = s[0].split('\\n')                         \n",
    "                    t = [s[1].strip(), s[0].strip(), wiki_url]                         \n",
    "                if re.search('\\n', t[1]):\n",
    "                    t = t[1].split('\\n')\n",
    "                    t = [t[1], t[0], wiki_url]                \n",
    "                director_films.add(tuple(t))                     \n",
    "        #Filmography Section has Number Movie (year) format\n",
    "        elif film.text[:1].isdigit() and re.search('\\(\\d\\d\\d\\d\\)', film.text):\n",
    "            film = film.text.rsplit(r')', 1)[0]\n",
    "            film = film.replace('(', ' ', 1)\n",
    "            director_films.add((film[:-6].strip(), film[-4:].strip(), wiki_url))            \n",
    "        #Filmography Section has Movie (year) format\n",
    "        elif  ')' in film:\n",
    "            film = film.text.rsplit(r' ', 1)[0]\n",
    "            film = film.replace('(', ' ', 1)\n",
    "            director_films.add((film[:-6].strip(), film[-4:].strip(), wiki_url))            \n",
    "        #Filmography Section has Year Movie format\n",
    "        elif film.text[:1].isdigit():\n",
    "            s = film.text.rsplit('(', 1)[0]\n",
    "            s = s.split(\":\")            \n",
    "            if len(s) >= 2:           \n",
    "                director_films.add((s[1].strip(), s[0].strip(), wiki_url))\n",
    "            else:\n",
    "                continue #print( \"WILL TRY TO FIX LATER OR IGNORE: \", film.text)\n",
    "        #Filmography Section has Movie year format\n",
    "        else:\n",
    "            bird = film.text.split(' (', 1)\n",
    "            tweet = re.search('\\d\\d\\d\\d', film.text)            \n",
    "            try:\n",
    "                tweet = str(tweet.group())\n",
    "            except:\n",
    "                tweet = \"0000\"\n",
    "            mxm = bird[0].strip(), tweet.strip(), wiki_url            \n",
    "            director_films.add(tuple(mxm))\n",
    "\n",
    "#print(director_films)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3679f7c0",
   "metadata": {},
   "source": [
    "#### This searches through people and tries to match person to Director via Movies  \n",
    "#### It then adds all the movies of a director to a Movie List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87619746",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMovies = pd.DataFrame(columns=['Movie_ID', 'Title', 'Year', 'Person_ID', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16967d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf = pd.DataFrame(director_films)\n",
    "rawdf.to_csv('raw_movie_wikipedia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "504fb16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "ia = Cinemagoer()\n",
    "person_id = []\n",
    "found = False\n",
    "\n",
    "#range is from 0 - length of directors: Only sections of the search at a time to avoid timeout issues\n",
    "# so it will sleep for 5 seconds every 50 searches done\n",
    "for i in range(0, len(names)): \n",
    "    \n",
    "    #add a wait time of 5 seconds so there isn't a timeout\n",
    "    if i % 50 == 0 and i > 0:\n",
    "        print(i)\n",
    "        time.sleep(5)\n",
    "\n",
    "    people = ia.search_person(names[i][0])\n",
    "    found = False\n",
    "    for person in people:\n",
    "        if found == False:\n",
    "            #print(person['name'])        \n",
    "            works = ia.get_person(people[0].personID)\n",
    "            #print (works['filmography'].keys())\n",
    "            if works.has_key('director'):\n",
    "                for job in works['filmography'].keys():\n",
    "                    if job == 'director': \n",
    "                        #print('Person ID:', person.personID, '\\tDirector:', person['name'], '\\t# Job:', job, )\n",
    "                        for movie in works['filmography'][job]:\n",
    "                            #print(movie, \" \", movie.get('year'))                        \n",
    "                            if next((i for i, v in enumerate(director_films) if v[0] == movie['title'] and v[1] == str(movie.get('year'))), None) and found == False:                             \n",
    "                                #print(\"test 1:\", '\\tID:%s Title:%s Year: %s' % (movie.movieID, movie['title'], movie['year']))  \n",
    "                                found = True                                                           \n",
    "                                for m in works['filmography'][job]:            \n",
    "                                    year = 0000 if 'year' not in m else int(m['year'])\n",
    "                                    #print(m['title'],'\\t', m['year'])\n",
    "                                    dfMovies.loc[len(dfMovies.index)] = [m.movieID, m['title'], year, person.personID, person['name']] \n",
    "                            elif next((i for i, v in enumerate(director_films) if v[0] == movie['title']), None) and found == False:\n",
    "                                #print (\"test 2:\", '\\tID:%s Title:%s Year: %s' % (movie.movieID, movie['title'], movie['year']) )\n",
    "                                found = True                                  \n",
    "                                for m in works['filmography'][job]:\n",
    "                                    year = 0000 if 'year' not in m else int(m['year'])\n",
    "                                    #print(m['title'],'\\t', m['year'])\n",
    "                                    dfMovies.loc[len(dfMovies.index)] = [m.movieID, m['title'], year, person.personID, person['name']]                            \n",
    "            else:\n",
    "                continue #print('Person ID:', person.personID, '\\tName:    ', person['name'], '\\t# Job:', job, \"(Doesn't have a filmography)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8d8089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMovies.to_csv(\"imdb_movies_directors.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f283105c72091a76353dc21b01dc7f03b7a16067dfb5107301ad30d44d65bd0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
